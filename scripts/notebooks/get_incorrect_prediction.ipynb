{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[9, 12, 15, 27, 32, 33, 39, 57, 59, 66, 71, 73]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load('best_model/b_g_labels_clean_train_lecfp4_fp.mlp')\n",
    "data_test = np.load('numpy_files/b_g_labels_clean_test_lecfp4_fp.npy')\n",
    "x_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# convert into list\n",
    "y_pred_list = y_pred.tolist()\n",
    "print(type(y_pred_list))\n",
    "incorrect_indices = [i for i in range(len(y_test)) if y_test[i] != y_pred[i]]\n",
    "print(incorrect_indices)\n",
    "# incorrect_label = [y_pred[i] for i in range(y_test) if y_test[i] != y_pred[i]]\n",
    "# true_label = [y_test[i] for i in range(y_test) if y_test[i] != y_pred[i]]\n",
    "\n",
    "# Get original CSV File\n",
    "test_df = pd.read_csv('data_clean/b_g_labels_clean_test.csv')\n",
    "# Insert predicted label on original CSV File\n",
    "\n",
    "test_df.insert(2, 'pred_Label', y_pred_list)\n",
    "# Save csv containing true and predicted labels\n",
    "\n",
    "test_df.to_csv('b_g_labels_clean_test_predicted.csv', index=False)\n",
    "\n",
    "# Filter and get dataframe with incorrect prediction.\n",
    "\n",
    "test_df_filtered = test_df[test_df.index.isin(incorrect_indices)]\n",
    "\n",
    "# Save the CSV file\n",
    "test_df_filtered.to_csv('b_g_labels_test_incorrect_predicted.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added: Find the TP, TN, FP, FN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7, 5, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to know how the threshold is used for 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load('best_model/b_g_labels_clean_train_lecfp4_fp.mlp')\n",
    "data_test = np.load('numpy_files/b_g_labels_clean_test_lecfp4_fp.npy')\n",
    "x_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.tolist()\n",
    "test_df = pd.read_csv('data_clean/b_g_labels_clean_test.csv')\n",
    "# Save the csv file with predicted label and probability\n",
    "y_pred_pro = model.predict_proba(x_test)\n",
    "y_pred_pro = y_pred_pro.tolist()\n",
    "test_smiles = test_df['Canonical_Smiles'].to_list()\n",
    "newdf = pd.DataFrame(list(zip(test_smiles, y_pred, y_pred_pro)), columns=['Canonical_Smiles', 'Predicted_label', 'Proba'])\n",
    "newdf.to_csv('predicted_test_with_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.97837088e-01, 2.16291177e-03],\n",
       "       [1.80209846e-01, 8.19790154e-01],\n",
       "       [9.96801496e-01, 3.19850393e-03],\n",
       "       [7.54024007e-01, 2.45975993e-01],\n",
       "       [8.95690825e-02, 9.10430918e-01],\n",
       "       [7.22439718e-02, 9.27756028e-01],\n",
       "       [4.67630832e-03, 9.95323692e-01],\n",
       "       [2.78897287e-02, 9.72110271e-01],\n",
       "       [9.99032729e-01, 9.67270893e-04],\n",
       "       [9.95317456e-01, 4.68254389e-03],\n",
       "       [9.92157202e-01, 7.84279780e-03],\n",
       "       [9.95773231e-01, 4.22676852e-03],\n",
       "       [9.99897667e-01, 1.02332993e-04],\n",
       "       [9.92982929e-01, 7.01707091e-03],\n",
       "       [9.29439359e-01, 7.05606410e-02],\n",
       "       [1.86567674e-01, 8.13432326e-01],\n",
       "       [9.99856756e-01, 1.43244126e-04],\n",
       "       [5.78482320e-03, 9.94215177e-01],\n",
       "       [9.95350890e-01, 4.64911036e-03],\n",
       "       [9.92540477e-01, 7.45952343e-03],\n",
       "       [9.99966657e-01, 3.33432321e-05],\n",
       "       [9.56665111e-01, 4.33348892e-02],\n",
       "       [8.43154666e-01, 1.56845334e-01],\n",
       "       [9.99538577e-01, 4.61423446e-04],\n",
       "       [1.27718610e-01, 8.72281390e-01],\n",
       "       [3.86850075e-01, 6.13149925e-01],\n",
       "       [4.19433064e-02, 9.58056694e-01],\n",
       "       [4.70192775e-01, 5.29807225e-01],\n",
       "       [9.98690728e-01, 1.30927170e-03],\n",
       "       [9.99941109e-01, 5.88910999e-05],\n",
       "       [9.74187942e-01, 2.58120580e-02],\n",
       "       [3.82824812e-03, 9.96171752e-01],\n",
       "       [3.05827320e-01, 6.94172680e-01],\n",
       "       [1.26181411e-02, 9.87381859e-01],\n",
       "       [9.47982241e-01, 5.20177595e-02],\n",
       "       [9.86043568e-01, 1.39564320e-02],\n",
       "       [1.33139895e-01, 8.66860105e-01],\n",
       "       [9.99915268e-01, 8.47324966e-05],\n",
       "       [9.99701956e-01, 2.98043744e-04],\n",
       "       [4.46391323e-01, 5.53608677e-01],\n",
       "       [1.92178876e-01, 8.07821124e-01],\n",
       "       [8.62483885e-01, 1.37516115e-01],\n",
       "       [9.99913846e-01, 8.61543995e-05],\n",
       "       [9.79687448e-01, 2.03125522e-02],\n",
       "       [9.95913095e-01, 4.08690539e-03],\n",
       "       [3.27031159e-01, 6.72968841e-01],\n",
       "       [9.98695201e-01, 1.30479895e-03],\n",
       "       [9.95002042e-01, 4.99795769e-03],\n",
       "       [4.69107866e-01, 5.30892134e-01],\n",
       "       [1.52568404e-01, 8.47431596e-01],\n",
       "       [9.99465316e-01, 5.34683515e-04],\n",
       "       [2.33323496e-01, 7.66676504e-01],\n",
       "       [9.80333479e-01, 1.96665212e-02],\n",
       "       [9.99955809e-01, 4.41909909e-05],\n",
       "       [9.63966708e-01, 3.60332921e-02],\n",
       "       [9.97611985e-01, 2.38801529e-03],\n",
       "       [9.96197685e-01, 3.80231524e-03],\n",
       "       [9.90737754e-01, 9.26224585e-03],\n",
       "       [9.95389015e-01, 4.61098544e-03],\n",
       "       [9.99617581e-01, 3.82419477e-04],\n",
       "       [1.82256561e-01, 8.17743439e-01],\n",
       "       [9.99469617e-01, 5.30382517e-04],\n",
       "       [9.99282616e-01, 7.17383599e-04],\n",
       "       [9.90101656e-01, 9.89834409e-03],\n",
       "       [9.99417986e-01, 5.82013668e-04],\n",
       "       [9.99686140e-01, 3.13859689e-04],\n",
       "       [3.85178854e-01, 6.14821146e-01],\n",
       "       [9.99255675e-01, 7.44324943e-04],\n",
       "       [2.84460203e-01, 7.15539797e-01],\n",
       "       [9.98889912e-01, 1.11008816e-03],\n",
       "       [1.20639050e-01, 8.79360950e-01],\n",
       "       [9.98498657e-01, 1.50134303e-03],\n",
       "       [1.10870821e-01, 8.89129179e-01],\n",
       "       [1.40086711e-01, 8.59913289e-01],\n",
       "       [9.63901059e-01, 3.60989408e-02],\n",
       "       [9.98646687e-01, 1.35331274e-03]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[9, 12, 15, 27, 32, 33, 39, 57, 59, 66, 71, 73]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load('../best_models/b_g_labels_clean_train_lecfp4_fp.mlp')\n",
    "data_test = np.load('../featues_test/b_g_labels_clean_test_lecfp4_fp_test.npy')\n",
    "x_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# convert into list\n",
    "y_pred_list = y_pred.tolist()\n",
    "print(type(y_pred_list))\n",
    "incorrect_indices = [i for i in range(len(y_test)) if y_test[i] != y_pred[i]]\n",
    "print(incorrect_indices)\n",
    "# incorrect_label = [y_pred[i] for i in range(y_test) if y_test[i] != y_pred[i]]\n",
    "# true_label = [y_test[i] for i in range(y_test) if y_test[i] != y_pred[i]]\n",
    "\n",
    "# Get original CSV File\n",
    "test_df = pd.read_csv('../data_clean/b_g_labels_clean_test.csv')\n",
    "# Insert predicted label on original CSV File\n",
    "\n",
    "test_df.insert(2, 'pred_Label', y_pred_list)\n",
    "# Save csv containing true and predicted labels\n",
    "\n",
    "test_df.to_csv('../check/b_g_labels_clean_test_predicted_test.csv', index=False)\n",
    "\n",
    "# Filter and get dataframe with incorrect prediction.\n",
    "\n",
    "test_df_filtered = test_df[test_df.index.isin(incorrect_indices)]\n",
    "\n",
    "# Save the CSV file\n",
    "test_df_filtered.to_csv('../check/b_g_labels_test_incorrect_predicted_test.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biasnet_clean_plot.ipynb\r\n",
      "biasnet_data_cleaning_and_splitting.ipynb\r\n",
      "get_fingerprints.py\r\n",
      "get_important_features.ipynb\r\n",
      "get_incorrect_prediction.ipynb\r\n",
      "long_fp.py\r\n",
      "trainClass.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load('../best_models/b_g_labels_clean_train_lecfp4_fp.mlp')\n",
    "data_test = np.load('../featues_test/b_g_labels_clean_test_one_lecfp4_fp.npy')\n",
    "x_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "print(len(y_test))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.tolist()\n",
    "test_df = pd.read_csv('../data_clean/b_g_labels_clean_test.csv')\n",
    "# Save the csv file with predicted label and probability\n",
    "y_pred_pro = model.predict_proba(x_test)\n",
    "y_pred_pro = y_pred_pro.tolist()\n",
    "print(len(y_pred_pro))\n",
    "test_smiles = test_df['Canonical_Smiles'].to_list()\n",
    "newdf = pd.DataFrame(list(zip(test_smiles, y_pred, y_pred_pro)), columns=['Canonical_Smiles', 'Predicted_label', 'Proba'])\n",
    "newdf.to_csv('../check/predicted_test_with_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Govindakc/opt/anaconda3/envs/biasnet/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/Govindakc/opt/anaconda3/envs/biasnet/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load('../best_models/b_g_labels_clean_train_lecfp4_fp.mlp')\n",
    "data_test = np.load('../featues_test/test_dan.npy')\n",
    "x_test = data_test\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.tolist()\n",
    "test_df = pd.read_csv('../data_clean/b_g_labels_clean_test.csv')\n",
    "# Save the csv file with predicted label and probability\n",
    "y_pred_pro = model.predict_proba(x_test)\n",
    "y_pred_pro = y_pred_pro.tolist()\n",
    "print(len(y_pred_pro))\n",
    "test_smiles = test_df['Canonical_Smiles'].to_list()\n",
    "newdf = pd.DataFrame(list(zip(test_smiles, y_pred, y_pred_pro)), columns=['Canonical_Smiles', 'Predicted_label', 'Proba'])\n",
    "newdf.to_csv('../check/predicted_test_with_proba_dan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Govindakc/opt/anaconda3/envs/biasnet/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/Govindakc/opt/anaconda3/envs/biasnet/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load('../best_models/b_g_labels_clean_train_lecfp4_fp.mlp')\n",
    "data_test = np.load('../biasnet_one/one_comp_lecfp4_fp.npy')\n",
    "x_test = data_test[:,:-1]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.tolist()\n",
    "test_df = pd.read_csv('../data_clean/b_g_labels_clean_test.csv')\n",
    "# Save the csv file with predicted label and probability\n",
    "y_pred_pro = model.predict_proba(x_test)\n",
    "y_pred_pro = y_pred_pro.tolist()\n",
    "print(len(y_pred_pro))\n",
    "test_smiles = test_df['Canonical_Smiles'].to_list()\n",
    "newdf = pd.DataFrame(list(zip(test_smiles, y_pred, y_pred_pro)), columns=['Canonical_Smiles', 'Predicted_label', 'Proba'])\n",
    "newdf.to_csv('../check/predicted_test_with_proba_dandan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
